{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "px.defaults.template = 'seaborn'\n",
    "px.defaults.width = 700\n",
    "px.defaults.height = 500\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "df = pd.read_csv('Automobile price data _Raw_.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data and encoding the ordinal columns\n",
    "df['normalized-losses'].replace('?', np.nan, inplace=True)\n",
    "df['normalized-losses'].fillna(df['normalized-losses'].median(), inplace=True)\n",
    "df['normalized-losses'] = df['normalized-losses'].astype('int')\n",
    "\n",
    "df.replace({'num-of-doors': '?'}, np.nan, inplace=True)\n",
    "df.dropna(subset=['num-of-doors'], inplace=True)\n",
    "df['num-of-doors'] = df['num-of-doors'].replace(['four', 'two'], [4, 2])\n",
    "df['num-of-doors'].dtype\n",
    "\n",
    "df['num-of-cylinders'] = df['num-of-cylinders'].replace(['four', 'six', 'five', 'eight', 'two', 'twelve', 'three'],\n",
    "                                                        [4, 6, 5, 8, 2, 12, 3])\n",
    "\n",
    "filt = df['bore'] != '?'\n",
    "df = df[filt]\n",
    "df['bore'] = df['bore'].astype('float')\n",
    "\n",
    "df['stroke'] = pd.to_numeric(df['stroke'])\n",
    "\n",
    "df['horsepower'] = df['horsepower'].replace('?', np.nan)\n",
    "df.dropna(subset=['horsepower'], inplace=True)\n",
    "df['horsepower'] = pd.to_numeric(df['horsepower'])\n",
    "\n",
    "df['peak-rpm'] = df['peak-rpm'].astype('float')\n",
    "\n",
    "df = df[df['price'] != '?']\n",
    "df['price'] = df['price'].astype('float')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df.apply(lambda x: len(x.value_counts()))\n",
    "df_value_counts = pd.DataFrame([value_counts, df.dtypes]).T\n",
    "df_value_counts.columns = ['unique_values', 'dtype']\n",
    "df_value_counts = df_value_counts.sort_values('unique_values')\n",
    "fig = px.bar(df_value_counts,x=df_value_counts.index, color='dtype', y='unique_values')\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('price')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Distribution\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "from scipy.stats import skew , kurtosis\n",
    "\n",
    "print('no transform')\n",
    "print('skew: ', round(skew(y), 2))\n",
    "print('kurtosis', round(kurtosis(y), 2))\n",
    "print()\n",
    "\n",
    "y_ = np.log(y)\n",
    "print('log transform')\n",
    "print('skew: ', round(skew(y_), 2))\n",
    "print('kurtosis', round(kurtosis(y_), 2))\n",
    "print()\n",
    "\n",
    "y_ = np.sqrt(y)\n",
    "print('sqrt transform')\n",
    "print('skew: ', round(skew(y_), 2))\n",
    "print('kurtosis', round(kurtosis(y_), 2))\n",
    "print()\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "trans = PowerTransformer(method='box-cox')\n",
    "y_ = trans.fit_transform(y[:,None])\n",
    "print('box-cox transformation')\n",
    "print('skew: ', round(skew(y_)[0], 2))\n",
    "print('kurtosis', round(kurtosis(y_)[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrying box cox transformation forward\n",
    "trans = PowerTransformer(method='box-cox')\n",
    "y_train_trans = trans.fit_transform(y_train[:,None])\n",
    "pd.DataFrame(y_train_trans).hist()\n",
    "plt.title('train')\n",
    "y_test_trans = trans.transform(y_test[:,None])\n",
    "pd.DataFrame(y_test_trans).hist()\n",
    "plt.title('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    print('Train r2 score: ', r2_score(y_train, model.predict(X_train)))\n",
    "    print('Test r2 score: ', r2_score(y_test, model.predict(X_test)))\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    fig.suptitle('Prediction vs Actual')\n",
    "    fig.add_subplot(121)\n",
    "    sns.scatterplot(x=y_train, y = model.predict(X_train))\n",
    "    plt.title('train set')\n",
    "    fig.add_subplot(122)\n",
    "    sns.scatterplot(x=y_test, y = model.predict(X_test), color='red')\n",
    "    plt.title('test set')\n",
    "    #fig = plt.figure(figsize=(12,6))\n",
    "    #fig.suptitle('Residual Error & homoscedasticity')\n",
    "    #fig.add_subplot(121)\n",
    "    #sns.scatterplot(x=y_train, y = (y_train-model.predict(X_train)))\n",
    "    #plt.title('train set')\n",
    "    #fig.add_subplot(122)\n",
    "    #sns.scatterplot(x=y_test, y = (y_test-model.predict(X_test)), color='red')\n",
    "    #plt.title('test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def generate_ridge_model(**kwargs):\n",
    "    ct = ColumnTransformer([(\"onehot\", OneHotEncoder(sparse=False, handle_unknown ='ignore'), X.select_dtypes('object').columns),\n",
    "                            (\"standard_scaler\", StandardScaler(), X.select_dtypes(exclude='object').columns)])\n",
    "    model = TransformedTargetRegressor(regressor=Ridge(**kwargs), transformer=PowerTransformer(method='box-cox'))\n",
    "    pipe = Pipeline([('feature_transformation', ct),\n",
    "                     ('model', model)])\n",
    "    return pipe\n",
    "\n",
    "def generate_random_forrest_model(**kwargs):\n",
    "    ct = ColumnTransformer([(\"onehot\", OneHotEncoder(sparse=False, handle_unknown ='ignore'), X.select_dtypes('object').columns),\n",
    "                            (\"standard_scaler\", StandardScaler(), X.select_dtypes(exclude='object').columns)])\n",
    "    model = TransformedTargetRegressor(regressor=RandomForestRegressor(**kwargs), transformer=PowerTransformer(method='box-cox'))\n",
    "    pipe = Pipeline([('feature_transformation', ct),\n",
    "                     ('model', model)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = generate_ridge_model()\n",
    "parameters = {'model__regressor__alpha':[0.01, 0.1, 0.5, 1, 5, 10, 100, 1000, 10000]}\n",
    "gs = GridSearchCV(pipe, parameters, cv=5)\n",
    "gs.fit(X, y)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = generate_ridge_model(alpha=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X, y, cv=5))\n",
    "evaluate_model(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pipe = generate_random_forrest_model()\n",
    "parameters = {'model__regressor__n_estimators':[10, 50, 100, 200],\n",
    "              'model__regressor__criterion':['mse', 'mae'],\n",
    "              'model__regressor__max_depth':[None, 10, 20],\n",
    "              'model__regressor__min_samples_split' : [2, 4, 8],\n",
    "              'model__regressor__min_samples_leaf' : [1, 2, 4],\n",
    "             }\n",
    "gs = GridSearchCV(pipe, parameters, cv=5)\n",
    "gs.fit(X, y)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_score_)\n",
    "'''\n",
    "#Obtained output\n",
    "#{'model__regressor__criterion': 'mse', 'model__regressor__max_depth': None, 'model__regressor__min_samples_leaf': 1, 'model__regressor__min_samples_split': 2, 'model__regressor__n_estimators': 10}\n",
    "#0.6888227121958135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "pipe = generate_random_forrest_model(n_estimators=10,\n",
    "                                     criterion='mse',\n",
    "                                     max_depth=None,\n",
    "                                     min_samples_split=2,\n",
    "                                     min_samples_leaf=1)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(cross_val_score(pipe, X, y, cv=10))\n",
    "print('Train mae', mean_absolute_error(y_train, pipe.predict(X_train)))\n",
    "print('Test mae', mean_absolute_error(y_test, pipe.predict(X_test)))\n",
    "evaluate_model(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding what is going wrong with multiple cross validations\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10)\n",
    "train_index, test_index = list(kf.split(X))[4]\n",
    "\n",
    "X_train_issue, X_test_issue = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "y_train_issue, y_test_issue = y.iloc[train_index], y.iloc[test_index]\n",
    "pipe.fit(X_train_issue, y_train_issue)\n",
    "evaluate_model(pipe, X_train_issue, y_train_issue, X_test_issue, y_test_issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data on which prodiction is highly correlated\n",
    "filt = (pd.Series(y_test_issue) > 12500)\n",
    "pd.DataFrame(X_test_issue).loc[filt,:]\n",
    "#All nissan models going wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_issue.make.value_counts()\n",
    "#No nissan model available in the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified model insuring all models are in test as well as in train data\n",
    "X_stratified_train = []\n",
    "y_stratified_test = []\n",
    "def generate_stratified_split(df, target, stratified_on, test_size=0.2):\n",
    "    X_train_s = []\n",
    "    X_test_s = []\n",
    "    y_train_s = []\n",
    "    y_test_s = []\n",
    "    for _, df_ in df.groupby(stratified_on):\n",
    "        X_ = df_.copy()\n",
    "        y_ = X_.pop(target)\n",
    "        if len(X_)>1:\n",
    "            X_train_,X_test_,y_train_,y_test_ = train_test_split(X_,y_, test_size = test_size)\n",
    "        else:\n",
    "            X_train_,X_test_,y_train_,y_test_ = X_, X_, y_, y_\n",
    "        X_train_s.append(X_train_)\n",
    "        X_test_s.append(X_test_)\n",
    "        y_train_s.append(y_train_)\n",
    "        y_test_s.append(y_test_)\n",
    "    X_train_s = pd.concat(X_train_s, axis=0)\n",
    "    X_test_s = pd.concat(X_test_s, axis=0)\n",
    "    y_train_s = pd.concat(y_train_s, axis=0)\n",
    "    y_test_s = pd.concat(y_test_s, axis=0)\n",
    "    return X_train_s, X_test_s, y_train_s, y_test_s\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = generate_stratified_split(df, 'price', 'make', test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unique make in train set: ', X_train_s.make.nunique())\n",
    "print('unique make in test set: ', X_test_s.make.nunique())\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Model\n",
    "pipe = generate_ridge_model(alpha=1)\n",
    "\n",
    "pipe.fit(X_train_s, y_train_s)\n",
    "print(cross_val_score(pipe, pd.concat([X_train_s, X_test_s], axis=0), pd.concat([y_train_s, y_test_s], axis=0), cv=10))\n",
    "print('Train mae', mean_absolute_error(y_train_s, pipe.predict(X_train_s)))\n",
    "print('Test mae', mean_absolute_error(y_test_s, pipe.predict(X_test_s)))\n",
    "evaluate_model(pipe, X_train_s, y_train_s, X_test_s, y_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "feature_importance = permutation_importance(pipe, X_train_s, y_train_s,\n",
    "                        n_repeats=10,\n",
    "                        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(feature_importance['importances'].T, columns=X_train_s.columns).mean().sort_values()\n",
    "fi.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_s.columns) - 1):\n",
    "    columns_selected = fi.index[i:]\n",
    "    \n",
    "    ct = ColumnTransformer([(\"onehot\", OneHotEncoder(sparse=False, handle_unknown ='ignore'), X_train_s[columns_selected].select_dtypes('object').columns),\n",
    "                            (\"standard_scaler\", StandardScaler(), X_train_s[columns_selected].select_dtypes(exclude='object').columns)])\n",
    "    model = TransformedTargetRegressor(regressor=Ridge(alpha=1),\n",
    "                                       transformer=PowerTransformer(method='box-cox'))\n",
    "    pipe = Pipeline([('feature_transformation', ct),\n",
    "                     ('model', model)])\n",
    "    X_cv = pd.concat([X_train_s[columns_selected], X_test_s[columns_selected]], axis=0)\n",
    "    y_cv = pd.concat([y_train_s, y_test_s], axis=0)\n",
    "    \n",
    "    cv_score = cross_val_score(pipe, X_cv, y_cv, cv=5).mean()\n",
    "    print(f'number of features: {len(X_cv.columns)}', f' mean cv r2: {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.api as sm\n",
    "#X_sm = sm.add_constant(X_train)\n",
    "#model = sm.OLS(y_train_trans,X_sm).fit()\n",
    "#model.summary()\n",
    "#from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "#vif = pd.DataFrame(np.zeros((1,len(X.columns))),columns=X.columns)\n",
    "#vif.iloc[0,:] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
